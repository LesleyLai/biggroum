Hi Banjo,

could you deploy the new containers for the BigGroum search?

# Docker compose file:
<ATTACH>


# Resources for the containers:

Image name and tag: biggroum_search:2.1
Memory allocation: 8192MB
CPU needs: 8 CPUS
Persistent disk size: 10GB

Image name and tag: biggroum_srcfinder:2.1
Memory allocation: 8192MB
CPU needs: 2 CPUS
Persistent disk size: 10GB

Image name and tag: biggroum_frontend:2.1
Memory allocation: 2048MB
CPU needs: 2 CPUS
Persistent disk size: 10GB


# Data to attach to the containers
The container for *biggroum_search* mount data stores in the /persist folder of the container (see the docker-compose.yml)

I updated the data in: https://drive.google.com/file/d/1EntMDaxhIwK5rNoMFIueozJtObHXlq0f/view?usp=sharing

Extract the archive (tar xjf demo_meeting.tar.gz) and mount the folder demo_meeting to the /persist folder in the biggroum_search container.


# Test
Download the python script https://raw.githubusercontent.com/cuplv/biggroum/master/docker_compose/test.py.

The tests just use requests. You can install the dependecies downloading the https://raw.githubusercontent.com/cuplv/biggroum/master/docker_compose/requirements.txt file.
Intall the requirements with:

pip install -r requirements.txt

Run the test as:
python test.py --address 100.120.0.6 --search_port 30072  --srcsrv_port 30071

A correct output is:

*** Testing biggroum_search service...
*** SUCCESS!

*** Testing web server -- get src code...
*** SUCCESS!


Thank you,
Sergio

